{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1\n",
    "В этом задании мы:\n",
    "1. Вспомним Python: циклы, функции и рекурсию.\n",
    "2. Посоздаем тензоры, поиндексируем их.\n",
    "3. Вручную имплементируем One-Hot Encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспоминаем Python\n",
    "Перед тем, как нырнуть в глубинное обучение, вспомним азы: язык Python.\n",
    "Нам понадобится работать со списками и вложенными вызовами функций, попрактикуемся с этим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №1:\n",
    "\n",
    "Напишите функцию, которая принимает на вход массив и возвращает другой массив, состоящий только из уникальных элементов исходного массива.\n",
    "Проще говоря, функция должна вернуть уникальные элементы из исходного массива.\n",
    "\n",
    "Функция должна называться `unique_elements`. На вход функции будет передаваться стандартный тип `list` из Python. На выходе функции ожидается стандартный тип `list` из Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_elements(list_: list[int]) -> list[int]:\n",
    "    \n",
    "    return list(set(list_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №2:\n",
    "Напишите функцию для подсчета n-го числа Фиббоначчи.\n",
    "\n",
    "P.S формула n-го числа Фиббоначчи:\n",
    "\\begin{cases}\n",
    "F(0) = 0 \\\\\n",
    "F(1) = 1 \\\\\n",
    "F(n) = F(n-1) + F(n-2), \\quad \\text{для } n \\geq 2\n",
    "\\end{cases}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(n: int) -> int:\n",
    "    \n",
    "    fib_n = 0\n",
    "    if n >= 2:\n",
    "        fib_list = [0, 1]\n",
    "        for i in range(n-1):\n",
    "            sum_elem = fib_list[-1] + fib_list[-2]\n",
    "            \n",
    "            print(f\"fib_list[-1]: {fib_list[-1]}\")\n",
    "            print(f\"fib_list[-2]: {fib_list[-2]}\")\n",
    "            fib_list.append(sum_elem)\n",
    "            # print(fib_list[-1] + fib_list[-2])\n",
    "        fib_n = fib_list[-1]\n",
    "    else:\n",
    "        fib_n = n\n",
    "\n",
    "    return fib_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib_list[-1]: 1\n",
      "fib_list[-2]: 0\n",
      "fib_list[-1]: 1\n",
      "fib_list[-2]: 1\n",
      "fib_list[-1]: 2\n",
      "fib_list[-2]: 1\n",
      "fib_list[-1]: 3\n",
      "fib_list[-2]: 2\n",
      "fib_list[-1]: 5\n",
      "fib_list[-2]: 3\n",
      "fib_list[-1]: 8\n",
      "fib_list[-2]: 5\n",
      "fib_list[-1]: 13\n",
      "fib_list[-2]: 8\n",
      "fib_list[-1]: 21\n",
      "fib_list[-2]: 13\n",
      "fib_list[-1]: 34\n",
      "fib_list[-2]: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тензоры\n",
    "\n",
    "Перейдем ближе к DL. Нейросети оперируют понятием **тензора**.\n",
    "\n",
    "Тензор - это многомерная матрица.\n",
    "Попрактикуемся в работе с ними."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,  ..., 997, 998, 999],\n",
       "        [  0,   1,   2,  ..., 997, 998, 999],\n",
       "        [  0,   1,   2,  ..., 997, 998, 999],\n",
       "        ...,\n",
       "        [  0,   1,   2,  ..., 997, 998, 999],\n",
       "        [  0,   1,   2,  ..., 997, 998, 999],\n",
       "        [  0,   1,   2,  ..., 997, 998, 999]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(size=[1000, 1000], dtype=int) * torch.arange(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №3:\n",
    "Создайте тензор размера (5, 3), заполненный случайными целыми числами от -1 до 1.\n",
    "\n",
    "Запишите результат в переменную t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randint(-1, 2, (5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №4:\n",
    "Вам дана доска 1000x1000.\n",
    "Каждую строку в ней нумеруют от 0 до 999 включительно.\n",
    "Т.е. получится матрица вида\n",
    "```python\n",
    "[\n",
    "    [0, 1, ..., 999],\n",
    "    [0, 1, ..., 999],\n",
    "    ...\n",
    "]\n",
    "```\n",
    "Напишите код, который сгенерирует такую матрицу. Постарайтесь обойтись без циклов `for`.\n",
    "Запишите эту матрицу в переменную `result`.\n",
    "\n",
    "_Подсказка_: посмотрите в сторону метода `some_tensor.repeat((N, M))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.ones([1000, 1000]) * torch.arange(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №5:\n",
    "Напишите функцию, которая будет нормировать трехмерный тензор вдоль его двух последних осей.\n",
    "Если на вход передается тензор размером `(5, 2, 10)`, необходимо выполнить следующие шаги:\n",
    "- Для каждого из 5 срезов (плоскостей размером `2x10`) вычислить среднее значение и дисперсию всех элементов в этой плоскости.\n",
    "- Используя эти средние значения и дисперсии, нормировать все элементы в соответствующей плоскости.\n",
    "\n",
    "\n",
    "Приводим ниже код через циклы `for` - вам нужно написать решение без использования `for`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[258], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# data = torch.rand(5, 2, 10)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m)) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 19\u001b[0m out1 \u001b[38;5;241m=\u001b[39m \u001b[43mslow_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m out2 \u001b[38;5;241m=\u001b[39m fast_normalize(data)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# assert_close(out2, out1)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[258], line 3\u001b[0m, in \u001b[0;36mslow_normalize\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mslow_normalize\u001b[39m(x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m----> 3\u001b[0m         mean, std \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, x[i]\u001b[38;5;241m.\u001b[39mstd()\n\u001b[0;32m      4\u001b[0m         x[i] \u001b[38;5;241m=\u001b[39m (x[i] \u001b[38;5;241m-\u001b[39m mean) \u001b[38;5;241m/\u001b[39m std\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "def slow_normalize(x: torch.Tensor) -> torch.Tensor:\n",
    "    for i in range(x.shape[0]):\n",
    "        mean, std = x[i].mean(), x[i].std()\n",
    "        x[i] = (x[i] - mean) / std\n",
    "    return x\n",
    "\n",
    "\n",
    "def fast_normalize(x: torch.Tensor) -> torch.Tensor:\n",
    "    \n",
    "    s_norm = (x - x.mean(dim=1, keepdim=True)) / x.std(dim=1, keepdim=True)\n",
    "\n",
    "    return s_norm\n",
    "\n",
    "\n",
    "from torch.testing import assert_close\n",
    "\n",
    "data = torch.rand(5, 2, 10)\n",
    "out1 = slow_normalize(data)\n",
    "out2 = fast_normalize(data)\n",
    "# assert_close(out2, out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7071,  0.7071,  0.7071,  0.7071, -0.7071,  0.7071,  0.7071,\n",
       "          -0.7071, -0.7071, -0.7071],\n",
       "         [ 0.7071, -0.7071, -0.7071, -0.7071,  0.7071, -0.7071, -0.7071,\n",
       "           0.7071,  0.7071,  0.7071]],\n",
       "\n",
       "        [[ 0.7071,  0.7071, -0.7071,  0.7071,  0.7071, -0.7071, -0.7071,\n",
       "          -0.7071, -0.7071,  0.7071],\n",
       "         [-0.7071, -0.7071,  0.7071, -0.7071, -0.7071,  0.7071,  0.7071,\n",
       "           0.7071,  0.7071, -0.7071]],\n",
       "\n",
       "        [[ 0.7071,  0.7071,  0.7071,  0.7071, -0.7071,  0.7071,  0.7071,\n",
       "          -0.7071,  0.7071,  0.7071],\n",
       "         [-0.7071, -0.7071, -0.7071, -0.7071,  0.7071, -0.7071, -0.7071,\n",
       "           0.7071, -0.7071, -0.7071]],\n",
       "\n",
       "        [[-0.7071, -0.7071,  0.7071,  0.7071, -0.7071,  0.7071,  0.7071,\n",
       "          -0.7071,  0.7071, -0.7071],\n",
       "         [ 0.7071,  0.7071, -0.7071, -0.7071,  0.7071, -0.7071, -0.7071,\n",
       "           0.7071, -0.7071,  0.7071]],\n",
       "\n",
       "        [[ 0.7071, -0.7071,  0.7071, -0.7071, -0.7071, -0.7071, -0.7071,\n",
       "           0.7071, -0.7071,  0.7071],\n",
       "         [-0.7071,  0.7071, -0.7071,  0.7071,  0.7071,  0.7071,  0.7071,\n",
       "          -0.7071,  0.7071, -0.7071]]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.arange(5 * 4 * 3, dtype=torch.float32).reshape((5, 4, 3)) ** 2).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  1.0714,  2.1429,  3.2143,  4.2857,  5.3571,  6.4286,  7.5000,\n",
       "         8.5714,  9.6429, 10.7143, 11.7857, 12.8571, 13.9286, 15.0000])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, 15, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(5, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   1.,    1.,    1.,    1.,    1.,    1.,    1.,    1.,    1.,    1.],\n",
       "         [   1.,    1.,    1.,    1.,    1.,    1.,    1.,    1.,    1.,    1.]],\n",
       "\n",
       "        [[   2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.],\n",
       "         [   2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.]],\n",
       "\n",
       "        [[-100.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.],\n",
       "         [   4.,    4.,    4.,    4.,    4.,    4.,    4.,    4.,    4.,    4.]],\n",
       "\n",
       "        [[   8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.],\n",
       "         [   8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.]],\n",
       "\n",
       "        [[   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
       "         [ 100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.]]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2][0][0] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-17.8000,  10.2000,  10.2000,  10.2000,  10.2000,  10.2000,  10.2000,\n",
       "           10.2000,  10.2000,  10.2000],\n",
       "         [ 23.0000,  23.0000,  23.0000,  23.0000,  23.0000,  23.0000,  23.0000,\n",
       "           23.0000,  23.0000,  23.0000]]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.],\n",
       "        [  2.,   2.],\n",
       "        [ 26.,   4.],\n",
       "        [  8.,   8.],\n",
       "        [  0., 100.]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.]],\n",
       "\n",
       "        [[ 2.]],\n",
       "\n",
       "        [[ 4.]],\n",
       "\n",
       "        [[ 8.]],\n",
       "\n",
       "        [[50.]]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.mean(dim=(1, 2), keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1325e+00, -1.1325e+00, -1.0853e+00,  7.2707e-01, -3.8232e-04,\n",
       "           1.6779e+00, -2.7253e-01, -3.0278e-01,  1.1623e+00,  7.4044e-01],\n",
       "         [-8.5626e-01, -8.7998e-01, -5.8369e-03, -6.5061e-01, -5.2264e-01,\n",
       "           2.4790e+00, -4.9970e-01,  1.0396e+00, -8.4499e-02, -4.0075e-01]],\n",
       "\n",
       "        [[ 3.3708e-01, -9.8784e-01, -1.4087e+00,  2.9703e-01, -9.0077e-01,\n",
       "          -1.0392e+00, -1.0485e+00, -3.9487e-01,  1.2986e+00, -8.6167e-01],\n",
       "         [-5.0440e-01, -5.6060e-01,  1.7222e+00,  1.4355e+00,  3.1048e-01,\n",
       "           1.6770e+00,  2.9702e-01,  2.6257e-01,  9.2858e-01, -8.5951e-01]],\n",
       "\n",
       "        [[-7.8473e-01, -1.5916e+00,  1.0419e+00, -7.6645e-01,  6.9101e-01,\n",
       "           8.8511e-01,  1.3650e+00, -2.5212e-02, -8.5524e-01, -8.5813e-01],\n",
       "         [-1.1403e+00, -7.6061e-01,  4.7438e-01,  7.6070e-01, -3.6614e-01,\n",
       "          -1.4634e+00,  6.2056e-01,  1.7492e+00, -6.1732e-02,  1.0857e+00]],\n",
       "\n",
       "        [[ 1.8690e-01,  1.6028e-01, -1.1050e+00, -1.5205e+00,  1.2317e+00,\n",
       "          -1.1875e-01, -7.5482e-01,  9.7520e-01,  1.3347e+00,  1.3508e+00],\n",
       "         [ 6.4587e-01,  9.8603e-01, -1.6209e+00,  1.3961e-01, -1.0541e+00,\n",
       "           5.6030e-01, -5.2883e-01, -1.2744e+00,  1.0095e+00, -6.0356e-01]],\n",
       "\n",
       "        [[-1.4233e+00,  2.1845e-01,  1.0555e-01,  1.2474e+00,  9.9544e-01,\n",
       "          -1.1799e+00,  3.5574e-01,  1.5795e+00, -2.4188e-01, -1.3250e+00],\n",
       "         [-8.2786e-01,  9.9389e-02, -1.0338e+00, -4.5110e-01,  1.1365e+00,\n",
       "           1.4030e+00,  4.1769e-02,  1.0884e+00, -3.8023e-01, -1.4080e+00]]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_normalize(torch.Tensor(5, 2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [9.0000e+00, 1.6000e+01, 2.5000e+01],\n",
       "         [3.6000e+01, 4.9000e+01, 6.4000e+01],\n",
       "         [8.1000e+01, 1.0000e+02, 1.2100e+02]],\n",
       "\n",
       "        [[1.4400e+02, 1.6900e+02, 1.9600e+02],\n",
       "         [2.2500e+02, 2.5600e+02, 2.8900e+02],\n",
       "         [3.2400e+02, 3.6100e+02, 4.0000e+02],\n",
       "         [4.4100e+02, 4.8400e+02, 5.2900e+02]],\n",
       "\n",
       "        [[5.7600e+02, 6.2500e+02, 6.7600e+02],\n",
       "         [7.2900e+02, 7.8400e+02, 8.4100e+02],\n",
       "         [9.0000e+02, 9.6100e+02, 1.0240e+03],\n",
       "         [1.0890e+03, 1.1560e+03, 1.2250e+03]],\n",
       "\n",
       "        [[1.2960e+03, 1.3690e+03, 1.4440e+03],\n",
       "         [1.5210e+03, 1.6000e+03, 1.6810e+03],\n",
       "         [1.7640e+03, 1.8490e+03, 1.9360e+03],\n",
       "         [2.0250e+03, 2.1160e+03, 2.2090e+03]],\n",
       "\n",
       "        [[2.3040e+03, 2.4010e+03, 2.5000e+03],\n",
       "         [2.6010e+03, 2.7040e+03, 2.8090e+03],\n",
       "         [2.9160e+03, 3.0250e+03, 3.1360e+03],\n",
       "         [3.2490e+03, 3.3640e+03, 3.4810e+03]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5 * 4 * 3, dtype=torch.float32).reshape((5, 4, 3)) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 1.0000e+00, 4.0000e+00],\n",
       "         [9.0000e+00, 1.6000e+01, 2.5000e+01],\n",
       "         [3.6000e+01, 4.9000e+01, 6.4000e+01],\n",
       "         [8.1000e+01, 1.0000e+02, 1.2100e+02]],\n",
       "\n",
       "        [[1.4400e+02, 1.6900e+02, 1.9600e+02],\n",
       "         [2.2500e+02, 2.5600e+02, 2.8900e+02],\n",
       "         [3.2400e+02, 3.6100e+02, 4.0000e+02],\n",
       "         [4.4100e+02, 4.8400e+02, 5.2900e+02]],\n",
       "\n",
       "        [[5.7600e+02, 6.2500e+02, 6.7600e+02],\n",
       "         [7.2900e+02, 7.8400e+02, 8.4100e+02],\n",
       "         [9.0000e+02, 9.6100e+02, 1.0240e+03],\n",
       "         [1.0890e+03, 1.1560e+03, 1.2250e+03]],\n",
       "\n",
       "        [[1.2960e+03, 1.3690e+03, 1.4440e+03],\n",
       "         [1.5210e+03, 1.6000e+03, 1.6810e+03],\n",
       "         [1.7640e+03, 1.8490e+03, 1.9360e+03],\n",
       "         [2.0250e+03, 2.1160e+03, 2.2090e+03]],\n",
       "\n",
       "        [[2.3040e+03, 2.4010e+03, 2.5000e+03],\n",
       "         [2.6010e+03, 2.7040e+03, 2.8090e+03],\n",
       "         [2.9160e+03, 3.0250e+03, 3.1360e+03],\n",
       "         [3.2490e+03, 3.3640e+03, 3.4810e+03]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5 * 4 * 3, dtype=torch.float32).reshape((5, 4, 3)) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.1001e-06,  1.2107e-42, -2.0000e+00,  1.8750e+00,  3.6893e+19,\n",
       "           1.8568e+00,  3.6893e+19,  1.8264e+00, -1.0842e-19,  1.7839e+00],\n",
       "         [ 2.0000e+00,  1.7085e+00,  2.0000e+00,  1.5248e+00,  1.0842e-19,\n",
       "           1.5410e+00,  1.0842e-19,  1.7576e+00, -2.0000e+00,  1.8609e+00]],\n",
       "\n",
       "        [[-1.0842e-19,  1.9256e+00, -1.0842e-19,  1.9894e+00,  0.0000e+00,\n",
       "           1.9219e+00,  3.6893e+19,  1.8972e+00, -1.0842e-19,  1.8661e+00],\n",
       "         [-0.0000e+00,  1.8089e+00, -2.0000e+00,  1.7454e+00,  0.0000e+00,\n",
       "           1.6052e+00, -1.0842e-19,  1.3092e+00, -3.6893e+19,  1.6691e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  1.7865e+00,  0.0000e+00,  1.8674e+00,  0.0000e+00,\n",
       "           1.9136e+00, -0.0000e+00,  1.9580e+00,  0.0000e+00,  1.9297e+00],\n",
       "         [-0.0000e+00,  1.9009e+00, -0.0000e+00,  1.8670e+00, -0.0000e+00,\n",
       "           1.8048e+00, -0.0000e+00,  1.7304e+00,  0.0000e+00,  1.5683e+00]],\n",
       "\n",
       "        [[ 1.0842e-19,  1.4174e+00,  3.6893e+19,  1.6850e+00,  1.0842e-19,\n",
       "           1.7915e+00, -0.0000e+00,  1.8677e+00, -1.0842e-19,  1.9107e+00],\n",
       "         [ 2.0000e+00,  1.9512e+00, -1.0842e-19,  1.9329e+00, -3.6893e+19,\n",
       "           1.9024e+00,  3.6893e+19,  1.8672e+00, -3.6893e+19,  1.8030e+00]],\n",
       "\n",
       "        [[-0.0000e+00,  1.7240e+00, -0.0000e+00,  1.5525e+00, -2.0000e+00,\n",
       "           1.4492e+00, -2.0000e+00,  1.6917e+00, -1.0842e-19,  1.7935e+00],\n",
       "         [-1.0842e-19,  1.8678e+00, -2.0000e+00,  1.9094e+00, -2.0000e+00,\n",
       "           1.9482e+00,  1.0842e-19,  1.9347e+00, -1.0842e-19,  1.9032e+00]]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №6:\n",
    "Вам дан тензор `t` размерности (53, 192, 789), в котором зашит секретный пароль.\n",
    "Пароль хитро разбросан по тензору, но вы знаете, как его отыскать:\n",
    "- вдоль первой размерности нужно взять индексы, являющиеся точными квадратами\n",
    "- вдоль второй размерности нужно взять столько четных чисел (начиная с 0), сколько было в п.1;\n",
    "- вдоль третьей размерности нужно взять в обратном порядке столько элементов с конца, сколько было в п.2;\n",
    "\n",
    "Найдите тензор с паролем. Исходный тензор лежит в переменной `t`.\n",
    "\n",
    "Запишите тензор с паролем в переменную `password`.\n",
    "\n",
    "Для тестирования можете создать тензор так:\n",
    "```python\n",
    "torch.random.manual_seed(0)\n",
    "t = torch.randint(0, 100, (53, 192, 789))\n",
    "```\n",
    "\n",
    "_Подсказка_: если PyTorch не хочет разворачивать, попробуйте `.flip()`\n",
    "\n",
    "_Подсказка_: индексы, которые хотите забрать, можно положить в список - и передать список в виде `t[my_list]`\n",
    "\n",
    "P.S Точный квадрат - число, являющееся квадратом некоторого целого числа. Иными словами, квадратом является целое число, квадратный корень из которого извлекается нацело."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "t = torch.randint(0, 100, (53, 192, 789))\n",
    "\n",
    "\n",
    "def password(t: torch.Tensor) -> torch.Tensor:\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0, 100, (2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[34,  7, 30,  4],\n",
       "         [24,  6,  3,  4],\n",
       "         [93, 86, 77, 35]],\n",
       "\n",
       "        [[64, 56, 97, 52],\n",
       "         [61, 25, 52, 27],\n",
       "         [92,  2, 41,  5]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[8.6603, 6.0000, 8.5440, 1.7321],\n",
       "         [6.2450, 3.1623, 9.5394, 2.2361],\n",
       "         [6.9282, 9.9499, 9.4340, 9.7980]],\n",
       "\n",
       "        [[9.8995, 9.8995, 9.7980, 5.8310],\n",
       "         [9.4868, 6.5574, 3.7417, 1.7321],\n",
       "         [4.4721, 5.7446, 9.6437, 6.0000]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = a == a.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 2],\n",
       "        [0, 0, 3],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 2],\n",
       "        [0, 1, 3],\n",
       "        [0, 2, 0],\n",
       "        [0, 2, 1],\n",
       "        [0, 2, 2],\n",
       "        [0, 2, 3],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 0, 2],\n",
       "        [1, 0, 3],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 2],\n",
       "        [1, 1, 3],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 2, 2],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.nonzero(as_tuple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2999999999999998"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.3 % 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание №7:\n",
    "Реализуйте One Hot Encoder. Вам необходимо написать функцию, которая выполняет One Hot Encoding для одномерного тензора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Простейший One Hot Encoding для одной колонки.\n",
    "\n",
    "    Пример (можете тестировать этим кодом):\n",
    "    >>> from torch.testing import assert_close\n",
    "    >>> assert_close(ohe(torch.tensor([0, 1, 0, 1])), torch.tensor([[1, 0], [0, 1], [1, 0], [0, 1]]))\n",
    "    >>> assert_close(ohe(torch.tensor([0, 1, 2])), torch.tensor([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n",
    "\n",
    "    :param y: массив размера (N,).\n",
    "    :returns: массив размера (N, K), где K - число уникальных значений в y.\n",
    "    \"\"\"\n",
    "    return ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
